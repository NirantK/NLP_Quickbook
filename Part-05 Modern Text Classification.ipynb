{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Methods for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Classification is a very frequently seen challenge. This has several applications ranging from sentiment analysis, tagging and filtering news articles, and detecting fraud reviews (on websites such as Amazon) to name a few. \n",
    "\n",
    "For simplicity, we will be working with a sentiment analysis dataset. For same reasons, we evaluate accuracy as our only metric here. \n",
    "\n",
    "We have a curated set of movie reviews picked up from Imdb. Each review is marked as either positive or negative. Ofcourse, this marks the overall sentiment of each review. \n",
    "\n",
    "Beginning this section, we will incorporate more and more Machine Learning instead of relying on linguistics analysis alone. In writing this, I assume that you have some basic familiarity with Python packages like [scikit-learn](http://scikit-learn.org/). \n",
    "\n",
    "If you don't, that's fine too. The intent here is too give you a quick reference of how these APIs functions work and save your time in looking up what to learn. \n",
    "\n",
    "You can and must learn to use such functions well, even without knowing all the nitty gritty of underlying math. You can trust these functions as black boxes.\n",
    "\n",
    "### Simple Classifiers\n",
    "\n",
    "We begin by simply tries a few machine learning classifiers such as Logistic Regression, Naive Bayes, Decision Trees. \n",
    "Next, we try Random Forest and Extra Trees Classifier. For all of these implementations, we don't use anything except scikit-learn. \n",
    "\n",
    "\n",
    "### Optimizing Simple Classifiers\n",
    "\n",
    "We can tweak the simple classifiers above to improve their performance. For this, the most common method is to try several slightly different versions of the classifier. We do this by changing the parameters of our classifier. \n",
    "\n",
    "We will learn how to automate this \"search\" process for the best classifier parameters using *GridSearch* and *RandomizedSearch*\n",
    "\n",
    "### Ensemble Methods\n",
    "\n",
    "Ensemble several different classifiers means we will be using a group of models. It is a very popular and easy to understand machine learning technique. This is part of almost every winning Kaggle competition. \n",
    "\n",
    "Despite initial concerns of why this might be slow, some teams working on commercial software have begun using this in production software as well. This is because it requires very little overhead, is easy to parallelize, and allows for a built-in fallback of using a single model. \n",
    "\n",
    "We will look at some of the simplest ensembling techniques based on simple majority, also known as voting ensemble and build using that.\n",
    "\n",
    "In summary, this **Machine Learning for NLP** section covers simple classifiers, parameter optimization, and ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "# if you are using the fastAI environment, all of these imports work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None: self.total = tsize\n",
    "        self.update(b * bsize - self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, filename):\n",
    "    \"\"\"\n",
    "    Download data if the filename does not exist already\n",
    "    Uses Tqdm to show download progress\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "\n",
    "        dirname = os.path.dirname(filename)\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "\n",
    "        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
    "            urlretrieve(url, filename, reporthook=t.update_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download some data:\n",
    "data_url = 'http://files.fast.ai/data/aclImdb.tgz'\n",
    "# get_data(data_url, 'data/imdb.tgz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, *manually extract the files* please!\n",
    "The *.tgz* extension is equivalent to *.tar.gz* here. \n",
    "\n",
    "On Windows, you might need a software like *7z* \n",
    "On Linux, you can probably use *tar -xvcf imdb.tgz* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd())/'data'/'aclImdb'\n",
    "assert data_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to check that we have extracted the files at the correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n",
      "all\n",
      "neg\n",
      "pos\n",
      "all\n",
      "neg\n",
      "pos\n",
      "unsup\n"
     ]
    }
   ],
   "source": [
    "for pathroute in os.walk(data_path):\n",
    "    next_path = pathroute[1]\n",
    "    for stop in next_path:\n",
    "        print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This really badly written utility tells us that there are atleast two folders: `train` and `test`. Each of these folders in turn has atleast 3 folders:\n",
    "```bash\n",
    "Test\n",
    "|- all\n",
    "|- neg\n",
    "|- pos\n",
    "```\n",
    "and\n",
    "\n",
    "```bash\n",
    "Train\n",
    "|- all\n",
    "|- neg\n",
    "|- pos\n",
    "|- unsup\n",
    "```\n",
    "\n",
    "The pos and neg folders contain reviews which are positive and negative respectively. The `unsup` folder stands for unsupervised. They are useful for building language models, specially for Deep Learning. We will not use that here. Similarly, the folder `all` is redundant because these reviews are repeated in pos and neg folders. \n",
    "\n",
    "# Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path/'train'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_path):\n",
    "    \"\"\"read data into pandas dataframe\"\"\"\n",
    "    \n",
    "    def load_dir_reviews(reviews_path):\n",
    "        files_list = list(reviews_path.iterdir())\n",
    "        reviews = []\n",
    "        for filename in files_list:\n",
    "            f = open(filename, 'r', encoding='utf-8')\n",
    "            reviews.append(f.read())\n",
    "        return pd.DataFrame({'text':reviews})\n",
    "        \n",
    "    \n",
    "    pos_path = dir_path/'pos'\n",
    "    neg_path = dir_path/'neg'\n",
    "    \n",
    "    pos_reviews, neg_reviews = load_dir_reviews(pos_path), load_dir_reviews(neg_path)\n",
    "    \n",
    "    pos_reviews['label'] = 1\n",
    "    neg_reviews['label'] = 0\n",
    "    \n",
    "    merged = pd.concat([pos_reviews, neg_reviews])\n",
    "    df = merged.sample(frac=1.0) # shuffle the rows\n",
    "    df.reset_index(inplace=True) # don't carry index from previous\n",
    "    df.drop(columns=['index'], inplace=True) # drop the column 'index' \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path/'train'\n",
    "test_path = data_path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = read_data(train_path)\n",
    "test = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this movie was going to be good. It ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There was a time when Joel Schumacher was rank...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm astounded and dismayed by the number of re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had been waiting eagerly to see this movie, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is one of my favorite movies ever! along ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I thought this movie was going to be good. It ...      0\n",
       "1  There was a time when Joel Schumacher was rank...      0\n",
       "2  I'm astounded and dismayed by the number of re...      1\n",
       "3  I had been waiting eagerly to see this movie, ...      0\n",
       "4  this is one of my favorite movies ever! along ...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv(data_path/'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(data_path/'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['text'], train['label']\n",
    "X_test, y_test = test['text'], test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression\n",
    "The simplest of all, we replicate the exact steps which we saw from Chapter 01. \n",
    "\n",
    "Feature Extraction: \n",
    "- Bag of Words\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the Pipeline in our introductory section. Pipeline allows to queue multiple operations in one single Python object.\n",
    "\n",
    "#### !TIP\n",
    "We are able to call functions like `fit`, `predict` and `fit_transform` on our `Pipeline` objects because Pipeline automatically calls the corresponding function of the last component in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr_clf.fit(X=X_train, y=y_train) # note that .fit function calls are inplace, and the Pipeline is not re-assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predicted = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, we are calling the `predict` function on our Pipeline. The test reviews go through under the same pre-processing steps e.g. `CountVectorizer()` and `TfidfTransformer()` here as the reviews during training. \n",
    "\n",
    "This ease of simplicity makes `Pipeline` one of the most frequently used abstractions in software-grade machine learning. Users might prefer to execute each step independently, or build their own Pipeline equivalents in some research/experimentation use cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88312"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_acc = sum(lr_predicted == y_test)/len(lr_predicted)\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we find our model accuracy?**\n",
    "Let's take a quick look at what is happening in the line above. \n",
    "\n",
    "Consider that our predictions are: `[1, 1, 1]` and ground truth: `[1, 0, 1]`. The equality would return a simple list of boolean objects like: `[True, False, True]`. When we `sum` a boolean list in Python, it returns the number of True cases - giving us exact count of how many times did our model make correct predictions. \n",
    "\n",
    "Diving this value by the total number of predictions made (or, equally the number of test reviews) gives us our accuracy.\n",
    "\n",
    "Let's write the above two line logic into a simple, light weight function to calculate accuracy. This would prevent us from repeating the logic.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_acc(pipeline_clf):\n",
    "    predictions = pipeline_clf.predict(X_test)\n",
    "    assert len(y_test) == len(predictions)\n",
    "    return sum(predictions == y_test)/len(y_test), predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf',LR())])\n",
    "lr_clf.fit(X=X_train, y=y_train)\n",
    "lr_acc, lr_predictions = imdb_acc(lr_clf)\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the Ngram Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86596"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',LR())])\n",
    "lr_clf.fit(X=X_train, y=y_train)\n",
    "lr_acc, lr_predictions = imdb_acc(lr_clf)\n",
    "lr_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Why is the above called Naive? There are more powerful and complex methods involving Bayesian approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "mnb_clf = Pipeline([('vect', CountVectorizer()), ('clf',MNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81356"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf.fit(X=X_train, y=y_train)\n",
    "mnb_acc, mnb_predictions = imdb_acc(mnb_clf)\n",
    "mnb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add TF-IDF\n",
    "\n",
    "Now, let's try the above model with TF-IDF as another step after the Bag of Words (Unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82956"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',MNB())])\n",
    "mnb_clf.fit(X=X_train, y=y_train)\n",
    "mnb_acc, mnb_predictions = imdb_acc(mnb_clf)\n",
    "mnb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82992"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf',MNB())])\n",
    "mnb_clf.fit(X=X_train, y=y_train)\n",
    "mnb_acc, mnb_predictions = imdb_acc(mnb_clf)\n",
    "mnb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Ngram Range from 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8572"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',MNB())])\n",
    "mnb_clf.fit(X=X_train, y=y_train)\n",
    "mnb_acc, mnb_predictions = imdb_acc(mnb_clf)\n",
    "mnb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Fit Prior to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',MNB(fit_prior=False))])\n",
    "mnb_clf.fit(X=X_train, y=y_train)\n",
    "mnb_acc, mnb_predictions = imdb_acc(mnb_clf)\n",
    "mnb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we made small modifications to try out few combinations in our Pipeline. \n",
    "\n",
    "We thought of each combination which might improve our performance. Increasing the `ngram_range` did work, while changing prior from uniform to fitting it (by changing `fit_prior` to False) did not help at all. This approach is tedious, and slightly error-prone because it also relies too much on human intuition of underlying data the machine learning model to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we don't try Gaussian Naive Bayes?\n",
    "\n",
    "Gaussian Naive Bayes assumes that the underlying features matrix (our TF-IDF) is densely packed. Owing to the nature of text (where every word is a feature), this is not the case. Our TF-IDF matrix is not densely packed. \n",
    "\n",
    "Additionally, our feature matrix is not even close to a Gaussian distribution.  \n",
    "\n",
    "We don't use Gaussian Naive Bayes for text classification, because it would not meet our requirements and assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Prior work such as that by [T Joachims](https://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf) with over 9K citations recommend Support Vector Classifiers for text classification. \n",
    "\n",
    "It's difficult to estimate whether it will be equally effective for us or not based on such literature due to difference in dataset, pre-processing steps. Let's give it a shot nevertheless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',SVC())])\n",
    "svc_clf.fit(X=X_train, y=y_train)\n",
    "svc_acc, svc_predictions = imdb_acc(svc_clf)\n",
    "print(svc_acc) # 0.6562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While SVM works best with linearly separabale data (looks like our text is usually not linearly separable), we still wanted to give it a try for completeness. \n",
    "\n",
    "Here, SVM does not have a great performance, and took a really long time to train (~150x) of most other classifiers. We will not look at SVM for this particular dataset again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Baseed Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70396"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "dtc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',DTC())])\n",
    "dtc_clf.fit(X=X_train, y=y_train)\n",
    "dtc_acc, dtc_predictions = imdb_acc(dtc_clf)\n",
    "dtc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "rfc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',RFC())])\n",
    "rfc_clf.fit(X=X_train, y=y_train)\n",
    "rfc_acc, rfc_predictions = imdb_acc(rfc_clf)\n",
    "rfc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75268"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier as XTC\n",
    "xtc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',XTC())])\n",
    "xtc_clf.fit(X=X_train, y=y_train)\n",
    "xtc_acc, xtc_predictions = imdb_acc(xtc_clf)\n",
    "xtc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically Fine Tuning \n",
    "\n",
    "Let's focus on our best performing model: Logistic Regression and see if we can push it's performance a little more. \n",
    "\n",
    "The best performance for our model was **0.88312** accuracy earlier. \n",
    "\n",
    "We are using the phrases parameter-search and hyperparameter search interchangeably here. This is done to stay consistent with the Deep Learning vocabulary.\n",
    "\n",
    "We want to select the best performing configuration of our pipeline. Each configuration might be diffirent is small ways like removing stop words, including bigrams and trigrams or similar. \n",
    "\n",
    "The total number of such configurations can be fairly large running into few thousands. In addition to manually selecting few combinations to try, we can try all of these several thousand combinations *and* evaluate each combination. \n",
    "\n",
    "This is too slow for most small-scale experiments such as ours. In large experiments, the possible space can run into millions and several days of computing again making it cost and time prohibitive. \n",
    "\n",
    "I strongly urge you to read this blog on [Hyperparameter Tuning](https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/5/hyperparameter-tuning) to become familiar with the vocabulary and ideas in the space beyond what is discussed here. \n",
    "\n",
    "### RandomizedSearch\n",
    "\n",
    "An alternative was proposed by [*Bergstra & Bengio, 2012*](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf). They demonstrated that Random Search across a large hyperparameter space is more effective than manual (as we did for Multinomial Naive Bayes) and often as-effective or more effective than Grid Search. \n",
    "\n",
    "**How do we use it here?**\n",
    "We build on top of the results such as that of Bergstra et al. We break down our parameter search into two steps: \n",
    "Step 1: Randomized Search to go through a wide parameter combination space in a limited number of iterations \n",
    "Step 2: Use the results above to run a GridSearch in that slightly narrow space. \n",
    "\n",
    "We can repeat the above steps till we stop seeing improvements in our results, but we won't do that here. We leave that as an exercise to the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to prepare the param_grid?\n",
    "TK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = dict(clf__C=[50, 75, 85, 100], \n",
    "                  vect__stop_words=['english', None],\n",
    "                  vect__ngram_range = [(1, 1), (1, 3)],\n",
    "                  vect__lowercase = [True, False],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does cv do? Adding cv above causes use of StratifiedKFold for evaluation of the scoring metric\n",
    "What does n_iter do? \n",
    "What does scoring do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'clf__C': [50, 75, 85, 100], 'vect__stop_words': ['english', None], 'vect__ngram_range': [(1, 1), (1, 3)], 'vect__lowercase': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(lr_clf, param_distributions=param_grid, n_iter=5, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated cross-validation accuracy: 0.89132\n"
     ]
    }
   ],
   "source": [
    "print(f'Calculated cross-validation accuracy: {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the performance of this classifier on the ones which we have already seen, we need to train it on complete dataset and test it on the same split as earlier. We do this next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_clf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88424, array([0, 1, 1, ..., 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_acc(best_random_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the classifier performance improves by more than 1% by simply changing very few parameters. This is amazing. \n",
    "\n",
    "Let's see what parameters are here. In order to compare this, you would need to know the default values for all of the parameters. Alternatively, we can simply look at the parameters from the `param_grid` that we wrote and note the selected parameter values. For everything not in the grid, default values are chosen and remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random_clf.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that in the best classifier: \n",
    "    - the chosen C value in clf is 100, \n",
    "    - lowercase is set to False\n",
    "    - removing stop words is bad idea, and\n",
    "    - adding bigrams and trigrams helps\n",
    "    \n",
    "Observations like these are very specific to this dataset and classifier pipeline. In my experience, this can and does vary widely.\n",
    "\n",
    "We can also not assume that the values are always the best value when we run `RandomizedSearch` for so few iterations. The rule of thumb is to run it for **60 iterations** atleast, and use a much larger `param_grid` as well. \n",
    "\n",
    "We used RandomizedSearch to understand the broad layout of parameters we want to try. We add the best values for some of those to our pipeline itself and continue to experiment with values of other parameters. \n",
    "\n",
    "We will now run GridSearch for these selected parameters. Here, on a whim, I am choosing to include bigrams and trigrams while running grid search over the `parameter C` of LogisticRegression. \n",
    "\n",
    "**!TIP**\n",
    "\n",
    "I have not mentioned what the parameter `C` stands for or how it influences the classifier. This is definitely important to understand while doing manual parameter search. I could notice that changing `C` helps simply by trying out different values. \n",
    "\n",
    "But, our intention here is to automate as much as possible. I instead try varying values in `C` to try during our `RandomizedSearch`. We are trading off human learning time (maybe a few hours) with compute time (maybe a few extra minutes). This mindset saves us time and effort both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',LR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = dict(clf__C=[85, 100, 125, 150])\n",
    "grid_search = GridSearchCV(lr_clf, param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001B7102B10C0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Minicond...lp\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001B7102B10C0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Minicond...lp\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...01B7150CA268>))>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...01B7150CA268>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'a6f2e7c3cb634e10b16d91097af28c58']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'a6f2e7c3cb634e10b16d91097af28c58'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\ngrid_search.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\ngrid_search.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '%%time\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-44-9855dc574354>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>\n        result = <ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>, result=<ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<ipython-input-44-9855dc574354> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', 'grid_search.fit(X_train, y_train)')\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='grid_search.fit(X_train, y_train)')\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = 'grid_search.fit(X_train, y_train)'\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='grid_search.fit(X_train, y_train)', local_ns=None)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', 'grid_search.fit(X_train, y_train)', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', 'grid_search.fit(X_train, y_train)', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='grid_search.fit(X_train, y_train)', local_ns=None)\n   1225         # time execution\n   1226         wall_st = wtime()\n   1227         if mode=='eval':\n   1228             st = clock2()\n   1229             try:\n-> 1230                 out = eval(code, glob, local_ns)\n        out = undefined\n        code = <code object <module> at 0x000001B72D7D24B0, file \"<timed eval>\", line 1>\n        glob = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        local_ns = None\n   1231             except:\n   1232                 self.shell.showtraceback()\n   1233                 return\n   1234             end = clock2()\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<timed eval> in <module>()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ore='warn', scoring='accuracy',\n       verbose=0), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Sep 26 05:47:48 2018\nPID: 4472                   Python 3.6.6: D:\\Miniconda3\\envs\\nlp\\python.exe\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([    0,     1,     2, ..., 16685, 16686, 16687]), test=array([16641, 16643, 16644, ..., 24997, 24998, 24999]), verbose=0, parameters={'clf__C': 85}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y_train = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001D3E9EC6158>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        vocabulary = <class 'dict'> instance\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _sort_features(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), X=<16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary=<class 'dict'> instance)\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([      0,       1,       2, ..., 3696111, 3696112, 3696113],\n      dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py\", line 248, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py\", line 213, in _fit\n    **fit_params_steps[name])\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 875, in fit_transform\n    X = self._sort_features(X, vocabulary)\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 731, in _sort_features\n    X.indices = map_index.take(X.indices, mode='clip')\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Wed Sep 26 05:47:48 2018\nPID: 4472                   Python 3.6.6: D:\\Miniconda3\\envs\\nlp\\python.exe\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([    0,     1,     2, ..., 16685, 16686, 16687]), test=array([16641, 16643, 16644, ..., 24997, 24998, 24999]), verbose=0, parameters={'clf__C': 85}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y_train = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001D3E9EC6158>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        vocabulary = <class 'dict'> instance\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _sort_features(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), X=<16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary=<class 'dict'> instance)\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([      0,       1,       2, ..., 3696111, 3696112, 3696113],\n      dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\nlp\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Wed Sep 26 05:47:48 2018\nPID: 4472                   Python 3.6.6: D:\\Miniconda3\\envs\\nlp\\python.exe\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([    0,     1,     2, ..., 16685, 16686, 16687]), test=array([16641, 16643, 16644, ..., 24997, 24998, 24999]), verbose=0, parameters={'clf__C': 85}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y_train = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001D3E9EC6158>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        vocabulary = <class 'dict'> instance\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _sort_features(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), X=<16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary=<class 'dict'> instance)\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([      0,       1,       2, ..., 3696111, 3696112, 3696113],\n      dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001B7102B10C0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Minicond...lp\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001B7102B10C0, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'D:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...nlp\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Minicond...lp\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...01B7150CA268>))>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...01B7150CA268>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000001B7150CA268>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'a6f2e7c3cb634e10b16d91097af28c58']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'a6f2e7c3cb634e10b16d91097af28c58'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 25, 23, 40, 27, 639848, tzinfo=tzutc()), 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'session': 'a6f2e7c3cb634e10b16d91097af28c58', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '0a644ca9c93a422b8ffb37b847a55c64', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\ngrid_search.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\ngrid_search.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '%%time\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-44-9855dc574354>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>\n        result = <ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>, result=<ExecutionResult object at 1b72d7d5e48, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001B7176F58A0, file \"<ipython-input-44-9855dc574354>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<ipython-input-44-9855dc574354> in <module>()\n----> 1 get_ipython().run_cell_magic('time', '', 'grid_search.fit(X_train, y_train)')\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='grid_search.fit(X_train, y_train)')\n   2162             # This will need to be updated if the internal calling logic gets\n   2163             # refactored, or else we'll be expanding the wrong variables.\n   2164             stack_depth = 2\n   2165             magic_arg_s = self.var_expand(line, stack_depth)\n   2166             with self.builtin_trap:\n-> 2167                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = 'grid_search.fit(X_train, y_train)'\n   2168             return result\n   2169 \n   2170     def find_line_magic(self, magic_name):\n   2171         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='grid_search.fit(X_train, y_train)', local_ns=None)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', 'grid_search.fit(X_train, y_train)', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', 'grid_search.fit(X_train, y_train)', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='grid_search.fit(X_train, y_train)', local_ns=None)\n   1225         # time execution\n   1226         wall_st = wtime()\n   1227         if mode=='eval':\n   1228             st = clock2()\n   1229             try:\n-> 1230                 out = eval(code, glob, local_ns)\n        out = undefined\n        code = <code object <module> at 0x000001B72D7D24B0, file \"<timed eval>\", line 1>\n        glob = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DTC': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from pathlib import Path\\nimport pandas as pd\\nimp...the fastAI environment, all of these imports work', 'class TqdmUpTo(tqdm):\\n    def update_to(self, b=...l = tsize\\n        self.update(b * bsize - self.n)', 'def get_data(url, filename):\\n    \"\"\"\\n    Downloa...rlretrieve(url, filename, reporthook=t.update_to)', \"# Let's download some data:\\ndata_url = 'http://f...clImdb.tgz'\\n# get_data(data_url, 'data/imdb.tgz')\", \"data_path = Path(os.getcwd())/'data'/'aclImdb'\\nassert data_path.exists()\", 'for pathroute in os.walk(data_path):\\n    next_pa...1]\\n    for stop in next_path:\\n        print(stop)', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", 'def read_data(dir_path):\\n    \"\"\"read data into p...ce=True) # drop the column \\'index\\' \\n    return df', \"train_path = data_path/'train'\\ntest_path = data_path/'test'\", r\"get_ipython().run_cell_magic('time', '', 'train ...d_data(train_path)\\ntest = read_data(test_path)')\", 'test[:5]', \"# test.to_csv(data_path/'test.csv', index=False)\", \"# train.to_csv(data_path/'train.csv', index=False)\", \"X_train, y_train = train['text'], train['label']\\nX_test, y_test = test['text'], test['label']\", 'from sklearn.pipeline import Pipeline\\nfrom sklea...ion.text import CountVectorizer, TfidfTransformer', 'from sklearn.linear_model import LogisticRegression as LR', \"lr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\", \"get_ipython().run_cell_magic('time', '', 'lr_clf...re inplace, and the Pipeline is not re-assigned')\", 'lr_predicted = lr_clf.predict(X_test)', ...], 'LR': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {11:                                                 ... one of my favorite movies ever! along ...      1, 18: Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 20: 0.88312, 22: 0.879, 23: 0.86596, 25: 0.81356, 26: 0.82956, 27: 0.82992, 28: 0.8572, 29: 0.8572, ...}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RFC': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        local_ns = None\n   1231             except:\n   1232                 self.shell.showtraceback()\n   1233                 return\n   1234             end = clock2()\n\n...........................................................................\nC:\\Users\\nirantk\\Desktop\\nlp-python-deep-learning\\<timed eval> in <module>()\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ore='warn', scoring='accuracy',\n       verbose=0), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Sep 26 05:47:48 2018\nPID: 4472                   Python 3.6.6: D:\\Miniconda3\\envs\\nlp\\python.exe\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), 0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, {'score': make_scorer(accuracy_score)}, array([    0,     1,     2, ..., 16685, 16686, 16687]), array([16641, 16643, 16644, ..., 24997, 24998, 24999]), 0, {'clf__C': 85})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...lbert...\nName: text, Length: 25000, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...999    1\nName: label, Length: 25000, dtype: int64, scorer={'score': make_scorer(accuracy_score)}, train=array([    0,     1,     2, ..., 16685, 16686, 16687]), test=array([16641, 16643, 16644, ..., 24997, 24998, 24999]), verbose=0, parameters={'clf__C': 85}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No....0001,\n          verbose=0, warm_start=False))])>\n        X_train = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y_train = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N....0001,\n          verbose=0, warm_start=False))])>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...0.0001,\n          verbose=0, warm_start=False))]), X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001D3E9EC6158>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None, 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X = 0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object\n        y = 0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=0        Antitrust falls right into that categor...'t ac...\nName: text, Length: 16668, dtype: object, y=0        0\n1        0\n2        1\n3        1\n4   ...687    1\nName: label, Length: 16668, dtype: int64)\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n    874         if not self.fixed_vocabulary_:\n--> 875             X = self._sort_features(X, vocabulary)\n        X = <16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        self._sort_features = <bound method CountVectorizer._sort_features of ...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        vocabulary = <class 'dict'> instance\n    876 \n    877             n_doc = X.shape[0]\n    878             max_doc_count = (max_df\n    879                              if isinstance(max_df, numbers.Integral)\n\n...........................................................................\nD:\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _sort_features(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), X=<16668x3696114 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, vocabulary=<class 'dict'> instance)\n    726         map_index = np.empty(len(sorted_features), dtype=np.int32)\n    727         for new_val, (term, old_val) in enumerate(sorted_features):\n    728             vocabulary[term] = new_val\n    729             map_index[old_val] = new_val\n    730 \n--> 731         X.indices = map_index.take(X.indices, mode='clip')\n        X.indices = array([      0,       1,       2, ..., 3696111, 3696112, 3696113],\n      dtype=int32)\n        map_index.take = <built-in method take of numpy.ndarray object>\n    732         return X\n    733 \n    734     def _limit_features(self, X, vocabulary, high=None, low=None,\n    735                         limit=None):\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ec1bd0e775ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "grid_search.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Calculated cross-validation accuracy: {grid_search.best_score_} while random_search was {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_grid_clf = grid_search.best_estimator_\n",
    "best_grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_acc(best_grid_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost ~3% performance gain over the unoptimized model. This was despite the fact that we tried very few parameters to optimize itself. \n",
    "\n",
    "It is worth mentioning that we can and must repeat these steps (RandomizedSearch and GridSearch) to push the model accuracy even further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models \n",
    "**Ensembling models** is a very powerful technique to improve your model performance across a variety of Machine Learning tasks. \n",
    "\n",
    "In the section below, I borrow heavily from the [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/) written by [MLWave](https://mlwave.com/).\n",
    "\n",
    "I explain why ensembling helps reduce error, or improve accuracy. I demonstrate all the popular techniques on our chosen task and dataset. While each of these techniques might not result in a performance gain for us specifically on our dataset, they are a powerful tool in your mental toolkit.  \n",
    "\n",
    "To ensure that you understand these techniques, I strongly urge you to try them on a few datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble\n",
    "\n",
    "### Simple Majority (aka Hard Voting)\n",
    "The simplest ensembling technique is perhaps to take a simple majority. This works on the intuition that a single model might make a error on a particular prediction, but several different models are unlikely to make identical errors. \n",
    "\n",
    "Let's look at an example. \n",
    "\n",
    "Ground truth: 1**1**011001\n",
    "\n",
    "Let's assume there are 3 models with only one error for this example\n",
    "\n",
    "Model A Prediction: 1**0**011001\n",
    "\n",
    "Model B Prediction: 1**1**011001\n",
    "\n",
    "Model C Prediction: 1**1**011001\n",
    "\n",
    "The majority votes gives us the correct answer in this example - \n",
    "\n",
    "Majority vote: 1**1**10110011\n",
    "\n",
    "---\n",
    "\n",
    "To try this on our dataset, we import the VotingClassifier from scikit-learn. VotingClassifier does not use the pre-trained models as inputs. It will call fit on the models or classifier pipelines, and use the predictions of all models to make the final prediction. \n",
    "\n",
    "To counter the hype in favour of ensembles elsewhere, we demonstrate that hard voting can actually hurt your accuracy performance. If someone claims that ensembling _always_ helps, you can quickly point them here to have a more constructive discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voting_clf = VotingClassifier(estimators=[('xtc', xtc_clf), ('rfc', rfc_clf)], voting='hard', n_jobs=-1)\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_voting_acc, _ = imdb_acc(voting_clf)\n",
    "hard_voting_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only two classifiers for demonstration, we use the eXtra Trees and Random Forest Classifiers. Individually, each of these classifiers have their performance capped at ~74% accuracy. \n",
    "\n",
    "In this particular example, the performance of the voting classifier is worse than both of them alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft voting predicts the class label based on class probabilities. The sums of the predicted probabilities for each classifier is calculated for each class (important, in case of multi-class). The assigned class is then the class with maximum probability sum or argmax(p_sum). \n",
    "\n",
    "This is recommended for an ensemble of well-calibrated classifiers. \n",
    "\n",
    "    Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. - from the [Callibration Docs on sklearn](http://scikit-learn.org/stable/modules/calibration.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('mnb', mnb_clf)], voting='soft', n_jobs=-1)\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_acc, _ = imdb_acc(voting_clf)\n",
    "soft_voting_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_acc = soft_voting_acc - lr_acc\n",
    "if gain_acc > 0:\n",
    "    print(f'We see that the soft voting gives us an absolute accuracy gain of {gain_acc*100:.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Classifiers\n",
    "\n",
    "The only way for the inferior models to overrule the best model (expert) is for them to collectively (and confidently) agree on an alternative. \n",
    "\n",
    "- How can we avoid this scenario? We then use a weighted majority vote\n",
    "- Why weighing? Usually we want to give a better model more weight in a vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weighted_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('lr2', lr_clf),('rf', xtc_clf), ('mnb2', mnb_clf),('mnb', mnb_clf)], voting='soft', n_jobs=-1)\n",
    "weighted_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment with 'hard' voting instead of 'soft' voting. This will tell you how does the voting strategy influence the accuracy of our ensembled classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_voting_acc, _ = imdb_acc(weighted_voting_clf)\n",
    "weighted_voting_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_acc = weighted_voting_acc - lr_acc\n",
    "if gain_acc > 0:\n",
    "    print(f'We see that the weighted voting gives us an absolute accuracy gain of {gain_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What have we learnt so far?  \n",
    "- Simple majority based voting classifier can perform worse than individual models \n",
    "- Soft Voting works better than Hard voting\n",
    "- Weighing classifiers by simply repeating the classifiers can help\n",
    "\n",
    "So far, we have been selecting classifiers seemingly at random. This is less than ideal, specially when we are builing for commerical utility where very 0.001% gain matters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Correlated Classifiers \n",
    "\n",
    "To see this, let us take 3 simple models again. The ground truth is all 1s:\n",
    "\n",
    "`\n",
    "1111111100 = 80% accuracy\n",
    "1111111100 = 80% accuracy\n",
    "1011111100 = 70% accuracy\n",
    "`\n",
    "\n",
    "These models are highly correlated in their predictions. When we take a majority vote we see no improvement:\n",
    "\n",
    "`\n",
    "1111111100 = 80% accuracy\n",
    "`\n",
    "\n",
    "Now we compare to 3 less-performing, but highly uncorrelated models:\n",
    "\n",
    "`\n",
    "1111111100 = 80% accuracy\n",
    "0111011101 = 70% accuracy\n",
    "1000101111 = 60% accuracy\n",
    "`\n",
    "\n",
    "When we ensemble this with a majority vote we get:\n",
    "\n",
    "`\n",
    "1111111101 = 90% accuracy\n",
    "`\n",
    "\n",
    "We get an improvement which is much higher than any of our individual models. Low correlation between model predictions can lead to better performance. \n",
    "\n",
    "In practice, this is tricky to get right but worth investigating nevertheless. \n",
    "\n",
    "We leave this as an exercise for you to try. \n",
    "\n",
    "As a quick hint, you will need to find the correlations among predictions of different models and select pairs which are less correlated to each other (ideally less than 0.5) and yet having a high enough performance as individual models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(mnb_predictions, lr_predictions)[0][1] # this is too high a correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corr_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('mnb', mnb_clf)], voting='soft', n_jobs=-1)\n",
    "corr_voting_clf.fit(X_train, y_train)\n",
    "corr_acc, _ = imdb_acc(corr_voting_clf)\n",
    "print(corr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(dtc_predictions,xtc_predictions )[0][1] # this is looks like a low correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "low_corr_voting_clf = VotingClassifier(estimators=[('dtc', dtc_clf), ('xtc', xtc_clf)], voting='soft', n_jobs=-1)\n",
    "low_corr_voting_clf.fit(X_train, y_train)\n",
    "low_corr_acc, _ = imdb_acc(low_corr_voting_clf)\n",
    "print(low_corr_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary\n",
    "---\n",
    "\n",
    "We saw several new ideas from machine learning. The intention is here to demonstrate some of the most common classifiers. We see how to use them with one thematic idea: Translate text to a numerical representation and then feed to these classifier.\n",
    "\n",
    "This covers a very miniscule fraction of the possibilities which you can try, ranging from better feature extraction than Tfidf to tuning classifiers with GridSearch+RandomizedSearch as well as ensembling several classifiers.\n",
    "\n",
    "What Next?\n",
    "---\n",
    "This chapter was mostly focussed on pre-deep learning methods for both feature extraction and classification. \n",
    "\n",
    "Deep Learning methods allow us to use a single model, where the feature extraction and classification are both \"learned\" fromo the underlying data distribution. While a lot has been written about Deep Learning in Computer Vision, we do a very shallow, first introduction for Deep Learning in Natural Language Processing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
